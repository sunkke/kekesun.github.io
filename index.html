<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.2/css/bulma.min.css">
  <link rel="stylesheet" href="css/all.min.css">
  <title>孙科 | Ke Sun</title>
</head>

<body class="has-navbar-fixed-top">

  <nav class="navbar is-fixed-top is-white" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://kekesun.github.io/">
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-meteor"></i>
          </span>
          <span><strong>Ke Sun</strong></span>
        </span>
      </a>
  
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  
    <div id="navbarBasicExample" class="navbar-menu">
      <div class="navbar-start">
        <a class="navbar-item is-outlined">
          About
        </a>
  
        <a class="navbar-item">
          Experience
        </a>
  
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More
          </a>
  
          <div class="navbar-dropdown">
            <a class="navbar-item">
              <span class="icon">
                <i class="fas fa-envelope"></i>
              </span>
              <span class="ml-2">Contact</span>
            </a>
            <a class="navbar-item">
              <span class="icon">
                <i class="fas fa-file"></i>
              </span>
              <span class="ml-2">CV</span>
            </a>
            <a class="navbar-item">
              <span class="icon">
                <i class="fas fa-file"></i>
              </span>
              <span class="ml-2">简历</span>
            </a>
            <a class="navbar-item">
              <span class="icon">
                <i class="fas fa-graduation-cap"></i>
              </span>
              <span class="ml-2">Google Scholar</span>
            </a>
          </div>
        </div>
      </div>
  
    </div>
  </nav>

  <!-- whole column, 1/12 margin on both sides -->
  
  <div class="columns is-mobile is-gapless is-centered">
    <div class="column is-10-desktop is-7-widescreen is-7-fullhd">
      <!-- About Section -->
      <section class="section">
        <h1 class="title is-4">About</h1>

        <div class="columns is-vcentered"> 
          <div class="column is-10 has-text-grey">
            <p class="block" style="text-align:justify;">
              I am a senior Human-Computer Interaction (HCI) researcher and UI designer at Huawei.
              My work focuses on understanding and improving human performance in multiple scenarios, 
              defining platform interaction guidelines and standards, and building new sensing and intelligent interaction technologies. 
              These efforts lie in domains including touchscreen, cross-device, wearable computing, smart home, and intelligent cockpit.
              Some of these work has been shipped with millions of consumer products improving the user experience.
            </p>
            <p class="block" style="text-align:justify;">
              I completed my Ph.D. and B.S. in Computer Science at Tsinghua University. So I often use applied machine
              learning, signal processing, computer vision, interaction design and user experiment in my work.
            </p>
          </div>
          <div class="column is-2">
            <figure class="image" style="width:180px; margin-left:auto; margin-right:auto">
              <img class="is-rounded" src="images/portrait.jpg">
            </figure>
          </div>
        </div>
      </section>

      <!-- Experience Section -->
      <section class="section">
        <h1 class="title is-4">Experience</h1>
        
        <div class="tags has-addons">
          <span class="tag is-danger is-light">Huawei</span>
          <span class="tag">2019-present</span>
        </div>
        <div class="box">
          <h5 class="title is-5">Blah xxxxxxx</h5>
        </div>

        <div class="tags has-addons mt-6">
          <span class="tag is-link is-light">Tsinghua University</span>
          <span class="tag">2010-2019</span>
        </div>

        <!-- *** Float -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">Float: one-handed and touch-free target selection on smartwatches</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="has-text-justified">
                Float is a wrist-to-finger input approach that enables one-handed and touch-free interaction on the smartwatches with high efficiency and precision using only commercially-available built-in sensors.
                A user tilts the wrist to point and performs an in-air finger tap to click. 
                To detect hand gestures, we are the first to combine the photoplethysmogram (PPG) signal from the optical heart rate monitor with the accelerometer and gyroscope from the IMU.
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at CHI 2017
              </p>
            </div>
          </div>
          <!-- notifications -->
          <div class="notification">
            Glad to see that the idea and solution of Float - tilting wrist to point and using heart rate sensor + motion sensor to detect hand actions- 
            have also been adopted exactly by Apple to launch the feature <a href="https://www.apple.com/newsroom/2021/05/apple-previews-powerful-software-updates-designed-for-people-with-disabilities/" target="_blank">AssistiveTouch for Apple Watch</a>.
          </div>
        </div>

        <!-- *** Lip-Interact -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">Lip-Interact: Improving Mobile Device Interaction with Silent Speech Commands</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                Lip-Interact is an interaction technique that allows users to issue commands on their smartphone through silent speech. 
                Lip-Interact repurposes the front camera to capture the user's mouth movements and recognize commands with a deep learning model. 
                Our system supports 44 commands for accessing both system-level functionalities (launching apps, changing system settings) and application-level functionalities. 
                Lip-Interact help users access functionality efficiently in one step, enable one-handed input, and assist touch to make interactions more fluent.
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at UIST 2018
              </p>
            </div>
          </div>
        </div>

        <!-- *** 1D-Handwriting -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">One-Dimensional Handwriting: Inputting Letters and Words on Smart Glasses</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                1D Handwriting is a unistroke gesture technique enabling text entry on a one-dimensional interface.
                The challenge is to map two-dimensional handwriting to a reduced one-dimensional space, while achieving a balance between memorability and performance efficiency. 
                After an iterative design, we finally derive a set of ambiguous two-length unistroke gestures.
                Users studies show that 1D Handwriting significantly outperforms a selection-based technique  for both letter input and word input. With extensive training, text entry rate can reach 19.6 WPM.
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at CHI 2016, 
                <span class="icon-text">
                  <span class="icon">
                    <i class="fas fa-award"></i>
                  </span>
                  <span>Honorable Mention Award</span>
                </span>
              </p>
            </div>
          </div>
        </div>
        <!-- End of 1D handwriting -->

        <!-- *** Sparse keyboard -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">Exploring Low-Occlusion Qwerty Soft Keyboard Using Spatial Landmarks</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <figure class="image">
                <img src="images/portrait.jpg" style="height:160px; max-height:160px">
              </figure>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                Qwerty soft keyboards often consume a large portion of the touchscreen space, occluding the application view on the smartphone and requiring a separate input interface on the smartwatch. 
                To free up the screen real estate, we explore the concept of Sparse Keyboard and proposes two new ways of presenting the Qwerty soft keyboard. 
                The idea is to use users’ spatial memory and the reference effect of spatial landmarks on the graphical interface. 
                Our final design K3-SGK displays only three keys while L5-EYOCN displays only five line segments instead of the entire Qwerty layout. 
                To achieve this, we employ a user-centered computational design method: first study the reference effect of a single landmark key (line segment) from empirical data, then make assumptions to generalize the effect to multiple landmarks, and finally optimize the best designs.
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at TOCHI 2019
              </p>
            </div>
          </div>
        </div>
        <!-- End of Sparse Keyboard -->

        <!-- *** ATK -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">ATK: Enabling Ten-Finger Freehand Typing in Air Based on 3D Hand Tracking Data</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                ATK is a novel interaction technique that enables freehand ten-finger typing in the air based on 3D hand tracking data. 
                We followed an iterative approach in designing ATK. We first empirically investigated users' mid-air typing behavior, 
                and examined fingertip kinematics during tapping, correlated movement among fingers and 3D distribution of tapping endpoints. 
                Based on the findings, we proposed a probabilistic tap detection algorithm, 
                and augmented Goodman's input correction model to account for the ambiguity in distinguishing tapping finger.
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at UIST 2015
                </span>
              </p>
            </div>
          </div>
        </div>
        <!-- End of ATK -->

        <!-- *** ThermalRing -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">ThermalRing: Gesture and Tag Inputs Enabled by a Thermal Imaging Smart Ring</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                ThermalRing is a thermal imaging smart ring using low-resolution thermal camera for identity-anonymous, illumination-invariant, and power-efficient sensing of both dynamic and static gestures. 
                We also design ThermalTag, thin and passive thermal imageable tags that reflect the heat from the human hand. 
                ThermalTag can be easily made and applied onto everyday objects by users. 
                We develop sensing techniques for three typical input demands:drawing gestures for device pairing, click and slide gestures for device control, and tag scan gestures for quick access. 
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at CHI 2019
              </p>
            </div>
          </div>
        </div>
        <!-- End of ThermalRing -->

        <!-- *** Virtual Grasp -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                VirtualGrasp is a novel gestural approach to retrieve virtual objects in virtual reality. 
                Using VirtualGrasp, a user retrieves an object by performing a barehanded gesture as if grasping its physical counterpart. 
                The object-gesture mapping under this metaphor is of high intuitiveness, which enables users to easily discover, remember the gestures to retrieve the objects. 
                Progressively, we investigated the consensus of the object-gesture mapping across users, the expressivity of grasping gestures, and the learnability and performance of the approach. 
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at CHI 2018
              </p>
            </div>
          </div>
        </div>
        <!-- End of Virtual grasp -->

        <!-- *** Skin Motion -->
        <div class="box">
          <!-- project paper title -->
          <h5 class="title is-5" style="color:Coral;">SkinMotion: what does skin movement tell us?</h5>
          <!-- video and description -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <video autoplay loop muted>
                <source src="movie.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p style="text-align:justify;">
                With the increasing popularity of wearable computing, 
                emerging techniques allow novel interaction modalities to be transferred from portable devices to the human body itself. 
                We show an alternative interaction modality - SkinMotion.
                SkinMotion reconstructs human motions from skin-stretching movements. 
                We discuss the potential applications of SkinMotion. 
                In addition, we explore one specific instance -- finger motion detection using the skin movement on the dorsum of the hand. 
              </p>
            </div>
          </div>
          <!-- link buttons and publication info -->
          <div class="columns mb-0"> 
            <div class="column is-4 is-4-desktop is-3-widescreen is-3-fullhd has-background-white">
              <p class="buttons">
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-link"></i>
                  </span>
                  <span>DOI</span>
                </a>
                <a class="button is-small is-info is-inverted">
                  <span class="icon is-small">
                    <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Talk</span>
                </a>
              </p>
            </div>
            <div class="column is-8 is-8-desktop is-9-widescreen is-9-fullhd has-background-white	">
              <p class="is-size-6" style="color:SlateGrey;">
                Published at UbiComp Workshop 2016
              </p>
            </div>
          </div>
        </div>
        <!-- End of Skin Motion -->
      
      <!-- Experience Section End -->
      </section>
    <!-- Main Column End -->
    </div>
  
  <!-- whole column end -->
  </div> 

</body>
</html>